import { b as CopilotServiceAdapter, C as CopilotRuntimeChatCompletionRequest, a as CopilotRuntimeChatCompletionResponse } from '../langserve-0c6100e3.js';
export { c as RemoteChain, R as RemoteChainParameters } from '../langserve-0c6100e3.js';
export { convertServiceAdapterError } from './shared/index.js';
import { L as LangChainAdapter } from '../groq-adapter-c8aec5c5.js';
export { G as GoogleGenerativeAIAdapter, f as GroqAdapter, e as GroqAdapterParams, a as OpenAIAdapter, O as OpenAIAdapterParams, c as OpenAIAssistantAdapter, b as OpenAIAssistantAdapterParams, d as UnifyAdapter, U as UnifyAdapterParams } from '../groq-adapter-c8aec5c5.js';
import Anthropic from '@anthropic-ai/sdk';
import '../index-96b330da.js';
import '../graphql/types/base/index.js';
import 'rxjs';
import '@copilotkit/shared';
import 'openai';
import '@langchain/core/messages';
import '@langchain/core/tools';
import '@langchain/core/utils/stream';
import 'groq-sdk';

/**
 * Copilot Runtime adapter for Anthropic.
 *
 * ## Example
 *
 * ```ts
 * import { CopilotRuntime, AnthropicAdapter } from "@copilotkit/runtime";
 * import Anthropic from "@anthropic-ai/sdk";
 *
 * const copilotKit = new CopilotRuntime();
 *
 * const anthropic = new Anthropic({
 *   apiKey: "<your-api-key>",
 * });
 *
 * return new AnthropicAdapter({
 *   anthropic,
 *   promptCaching: {
 *     enabled: true,
 *     debug: true
 *   }
 * });
 * ```
 */

interface AnthropicPromptCachingConfig {
    /**
     * Whether to enable prompt caching.
     */
    enabled: boolean;
    /**
     * Whether to enable debug logging for cache operations.
     */
    debug?: boolean;
}
interface AnthropicAdapterParams {
    /**
     * An optional Anthropic instance to use.  If not provided, a new instance will be
     * created.
     */
    anthropic?: Anthropic;
    /**
     * The model to use.
     */
    model?: string;
    /**
     * Configuration for prompt caching.
     * See: https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching
     */
    promptCaching?: AnthropicPromptCachingConfig;
}
declare class AnthropicAdapter implements CopilotServiceAdapter {
    private model;
    private promptCaching;
    private _anthropic;
    get anthropic(): Anthropic;
    constructor(params?: AnthropicAdapterParams);
    /**
     * Adds cache control to system prompt
     */
    private addSystemPromptCaching;
    /**
     * Adds cache control to the final message
     */
    private addIncrementalMessageCaching;
    private shouldGenerateFallbackResponse;
    process(request: CopilotRuntimeChatCompletionRequest): Promise<CopilotRuntimeChatCompletionResponse>;
}

interface OllamaAdapterOptions {
    model?: string;
}
declare class ExperimentalOllamaAdapter implements CopilotServiceAdapter {
    private model;
    constructor(options?: OllamaAdapterOptions);
    process(request: CopilotRuntimeChatCompletionRequest): Promise<CopilotRuntimeChatCompletionResponse>;
}

/**
 * Copilot Runtime adapter for AWS Bedrock.
 *
 * ## Example
 *
 * ```ts
 * import { CopilotRuntime, BedrockAdapter } from "@copilotkit/runtime";
 *
 * const copilotKit = new CopilotRuntime();
 *
 * return new BedrockAdapter({
 *   model: "amazon.nova-lite-v1:0",
 *   region: "us-east-1",
 *   credentials: {
 *     accessKeyId: process.env.AWS_ACCESS_KEY_ID,
 *     secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
 *   }
 * });
 * ```
 */

interface BedrockAdapterParams {
    /**
     * AWS Bedrock model ID to use.
     * @default "amazon.nova-lite-v1:0"
     */
    model?: string;
    /**
     * AWS region where Bedrock is available.
     * @default "us-east-1"
     */
    region?: string;
    /**
     * AWS credentials for Bedrock access.
     */
    credentials?: {
        accessKeyId?: string;
        secretAccessKey?: string;
    };
}
declare class BedrockAdapter extends LangChainAdapter {
    constructor(options?: BedrockAdapterParams);
}

/**
 * CopilotKit Empty Adapter
 *
 * This adapter is meant to preserve adherence to runtime requirements, while doing nothing
 * Ideal if you don't want to connect an LLM the to the runtime, and only use your LangGraph agent.
 * Be aware that Copilot Suggestions will not work if you use this adapter
 *
 * ## Example
 *
 * ```ts
 * import { CopilotRuntime, EmptyAdapter } from "@copilotkit/runtime";
 *
 * const copilotKit = new CopilotRuntime();
 *
 * return new EmptyAdapter();
 * ```
 */

declare class EmptyAdapter implements CopilotServiceAdapter {
    process(request: CopilotRuntimeChatCompletionRequest): Promise<CopilotRuntimeChatCompletionResponse>;
}
declare const ExperimentalEmptyAdapter: typeof EmptyAdapter;

export { AnthropicAdapter, AnthropicAdapterParams, AnthropicPromptCachingConfig, BedrockAdapter, BedrockAdapterParams, CopilotRuntimeChatCompletionRequest, CopilotRuntimeChatCompletionResponse, CopilotServiceAdapter, EmptyAdapter, ExperimentalEmptyAdapter, ExperimentalOllamaAdapter, LangChainAdapter };
